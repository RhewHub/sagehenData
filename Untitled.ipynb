{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as \n",
    "import numpy as np\n",
    "import time\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_outliers_destr(lst, minimum, maximum):\n",
    "    while (np.min(lst) < minimum):\n",
    "        error = np.argmin(lst)\n",
    "        lst[error] = 0.5*(lst[error-1] + lst[error+1])\n",
    "    while (np.max(lst) > maximum):\n",
    "        error = np.argmax(lst)\n",
    "        lst[error] = 0.5*(lst[error-1] + lst[error+1])\n",
    "        \n",
    "def filter_outliers_newlist(lst, minimum, maximum):\n",
    "    new_lst = list(lst)\n",
    "    \n",
    "    while (np.min(new_lst) < minimum):\n",
    "        error = np.argmin(new_lst)\n",
    "        lst[error] = 0.5*(new_lst[error-1] + new_lst[error+1])\n",
    "    while (np.max(new_lst) > maximum):\n",
    "        error = np.argmax(new_lst)\n",
    "        new_lst[error] = 0.5*(new_lst[error-1] + new_lst[error+1])\n",
    "        \n",
    "    return new_lst\n",
    "\n",
    "def filter_spikes(data, min_roc, max_roc, toggle_nan=False):\n",
    "    fil_indices = []\n",
    "    old_values = []\n",
    "    new_values = []\n",
    "    \n",
    "    lst = list(data)\n",
    "    \n",
    "    diff = np.diff(lst)\n",
    "    i = 0\n",
    "    while (i < len(diff)):\n",
    "        if (diff[i] < min_roc):\n",
    "            fil_indices.append(i+1)\n",
    "            old_values.append(lst[i+1])\n",
    "            drops = 1\n",
    "            j = i + 1\n",
    "            while (diff[j] == 0):\n",
    "                fil_indices.append(j)\n",
    "                old_values.append(lst[j])\n",
    "                drops += 1\n",
    "                j += 1\n",
    "            if (toggle_nan):\n",
    "                for k in range(i+1, j+1):\n",
    "                    lst[k] = NaN\n",
    "                    new_values.append(lst[k])\n",
    "            else:\n",
    "                slope = (0.5*(lst[j+1] - lst[i])) / drops\n",
    "                for k in range(i+1, j+1):\n",
    "                    lst[k] = lst[k-1] + slope\n",
    "                    new_values.append(lst[k])\n",
    "            i = j\n",
    "        i += 1\n",
    "    filtered = list(zip(fil_indices, old_values, new_values))\n",
    "            \n",
    "    return lst, filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FOR Rate of Change errors ##\n",
    "\n",
    "def find_velocity_extremes_individual(data, threshold):\n",
    "    assert threshold > 0\n",
    "    data = data.astype(np.float)\n",
    "    extremes = []\n",
    "    for i in range(2, len(data)-1):\n",
    "        if not (np.isnan(np.array(data[i], dtype=np.float64)) or np.isnan(np.array(data[i+1], dtype=np.float64)) or np.isnan(np.array(data[i-1],dtype=np.float64))):\n",
    "            diff1 = abs(data[i] - data[i-1])\n",
    "            diff2 = abs(data[i+1] - data[i])\n",
    "            if (diff1 > threshold and diff2 > threshold):\n",
    "                extremes.append(i)\n",
    "                extremes.append(i+1) \n",
    "    return extremes\n",
    "\n",
    "def find_timestamp_ROC_errors(timestamps, data_header, extremes):\n",
    "    error_timestamps = []\n",
    "    for x in extremes:\n",
    "        error_timestamps.append((timestamps[x], data_header))\n",
    "    return error_timestamps\n",
    "\n",
    "def replace_velocity_extremes_individual_NaN(data, threshold):\n",
    "    extremes = find_velocity_extremes_individual(data, threshold)\n",
    "    for x in extremes:\n",
    "        data[x] = NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FOR '-9999' to NaN drops ##\n",
    "\n",
    "## Returns the number of '-9999' drops in one measurement.\n",
    "def find_measurement_drops(measurement):\n",
    "    return list(measurement).count(\"-9999\")\n",
    "\n",
    "## Returns the total number of '-9999' drops in a set of measurements.\n",
    "def find_total_drops(all_data):\n",
    "    drops = 0\n",
    "    for measurement in all_data:\n",
    "        drops += find_measurement_drops(measurement)\n",
    "    return drops\n",
    "\n",
    "## Prints the number of '-9999' drops in one measurement.\n",
    "def print_measurement_drops(measurement):\n",
    "    header = 0\n",
    "    if (measurement[header] != \" flag\" and measurement[header] != \"Timestamp\"):\n",
    "        print(measurement[header], \": \", find_measurement_drops(measurement))\n",
    "\n",
    "## Prints the number of '-9999' drops in each measurement in a set of measurements.\n",
    "def print_all_drops(all_data):\n",
    "    header = 0\n",
    "    for measurement in all_data:\n",
    "            print_measurement_drops(measurement)\n",
    "    print(\"TOTAL DROPS: \", find_total_drops(all_data), \"\\n\")\n",
    "\n",
    "## Filter and replace all '-9999' drops with 'NaN' values in one measurement.    \n",
    "def replace_drops_NaN(measurement):\n",
    "    measurment = measurement.tolist()\n",
    "    for i in range(1, len(measurement)):\n",
    "        if (measurement[i]== \"-9999\"):\n",
    "            measurement[i] = NaN\n",
    "    measurement = np.asarray(measurement)\n",
    "\n",
    "## Filter and replace all '-9999' drops with 'NaN' values for all measurements\n",
    "#  in a set of measurements.\n",
    "def replace_alldrops_NaN(all_data):\n",
    "    for measurement in all_data:\n",
    "        if (measurement[0] != \" flag\" and measurement[0] != \"Timestamp\"):\n",
    "            replace_drops_NaN(measurement)\n",
    "            \n",
    "## Return the indices of all drops in a measurement.\n",
    "def find_dropindex(measurement):\n",
    "    dropindices = []\n",
    "    measurment = measurement.tolist()\n",
    "    for i in range(1, len(measurement)):\n",
    "        if (measurement[i] == \"-9999\"):\n",
    "            dropindices.append(i)\n",
    "    measurement = np.asarray(measurement)\n",
    "    return dropindices\n",
    "\n",
    "## Return the timestamps of drops in a specified measurement (string).\n",
    "def find_timestamps_drops1(all_data, header):\n",
    "    droplist = []\n",
    "    headers = get_headers(all_data)\n",
    "    if header in headers.keys():\n",
    "        for x in find_dropindex(all_data[headers[header]]):\n",
    "            droplist.append(all_data[0][x])\n",
    "    return droplist        \n",
    "\n",
    "## Return the timestamps of drops in a specified measurement (numerical index).\n",
    "def find_timestamps_drops2(all_data, index):\n",
    "    assert (index % 2 == 1) and (index > 0) and (index < len(all_data))\n",
    "    droplist = []\n",
    "    for x in find_dropindex(all_data[index]):\n",
    "        droplist.append(all_data[0][x])\n",
    "    return droplist\n",
    "\n",
    "## Pair timestamps of every drop in a measurment with measurment header for every measurement.\n",
    "#  If drops exceed the tolerance print out the number of drops instead.\n",
    "def find_timestamps_drops_all(all_data, tolerance):\n",
    "    droplist = []\n",
    "    for measurement in all_data:\n",
    "        if (measurement[0] != \" flag\" and measurement[0] != \"Timestamp\"):\n",
    "            if (find_measurement_drops(measurement) < (tolerance*len(all_data[0]))):\n",
    "                droplist.append((measurement[0], find_timestamps_drops1(all_data, measurement[0])))\n",
    "            else:\n",
    "                droplist.append((measurement[0], \"\", find_measurment_drops(measurment)), \" drops\")\n",
    "    return dict(droplist)\n",
    "\n",
    "# Print out the header, timestamp pairing for every measurement\n",
    "def print_timestamps_drops_all(all_data, tolerance):\n",
    "    droplist = find_timestamps_drops_all(all_data, tolerance)\n",
    "    for x in droplist.keys():\n",
    "        print(x, \": \", droplist[x])\n",
    "\n",
    "# Return list of headers paired with indices in set.\n",
    "def get_headers(all_data):\n",
    "    headers = []\n",
    "    for i in range(1, len(all_data)):\n",
    "        headers.append((all_data[i][0], i))\n",
    "    return dict(headers)\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "## FOR \"-9999\" drops to be interpolated ##\n",
    "\n",
    "def interpolate_drops(measurement, dimensionality=0):\n",
    "    measurement = measurement.tolist()\n",
    "    if (dimensionality == 0):\n",
    "        for i in range(2, len(measurement)):\n",
    "            if (measurement[i] == \"-9999\"):\n",
    "                j = 1\n",
    "                while (measurement[i+j] == \"-9999\" and j < 6):\n",
    "                    j+=1\n",
    "                if (j == 6):\n",
    "                    while(measurement[i+j] == \"-9999\"):\n",
    "                        j+=1\n",
    "                    measurement[i:j-1] = NaN\n",
    "                    i += j+1\n",
    "                else:\n",
    "                    slope = (float(measurement[i+j]) - float(measurement[i-1])) / (j+1)\n",
    "                    for k in range(i, i+j):\n",
    "                        measurement[k] = float(measurement[k-1]) + slope\n",
    "            else:\n",
    "                i+=1\n",
    "    return np.asarray(measurement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_VB(data):\n",
    "    drops = []\n",
    "    for i in range(1, len(data)):\n",
    "        if (data[i] == \"VB\"):\n",
    "            drops.append(i)\n",
    "    print(len(drops))\n",
    "    return drops\n",
    "\n",
    "def replace(data, ind):\n",
    "    for x in ind:\n",
    "        data[x] = NaN\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_and_mean(inp, size):\n",
    "    data = inp[1:].astype(float)\n",
    "    out = np.zeros(int((len(data))/size) + 1)\n",
    "    i = 0\n",
    "    while (i < len(data)):\n",
    "        mean =  np.nanmean(data[i:(i+size-1)])\n",
    "        out[int(i/size)] = mean\n",
    "        i += size\n",
    "    return out\n",
    "\n",
    "def reduce_and_max(inp, size):\n",
    "    data = inp[1:].astype(float)\n",
    "    out = np.zeros(int((len(data))/size) + 1)\n",
    "    i = 0\n",
    "    while (i < len(data)):\n",
    "        maxv =  np.nanmax(data[i:(i+size-1)])\n",
    "        out[int(i/size)] = maxv\n",
    "        i += size\n",
    "    return out\n",
    "\n",
    "def reduce_and_min(inp, size):\n",
    "    data = inp[1:].astype(float)\n",
    "    out = np.zeros(int((len(data))/size) + 1)\n",
    "    i = 0\n",
    "    while (i < len(data)):\n",
    "        minv =  np.nanmin(data[i:(i+size-1)])\n",
    "        out[int(i/size)] = minv\n",
    "        i += size\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
